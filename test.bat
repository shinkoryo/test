# makedir
@echo off

setlocal enabledelayedexpansion
SET row=0
FOR /F "tokens=2" %%i IN (ListWorksFolderList.txt) DO (
  SET /a row+=1
  IF !row! gtr 1 MD .\temp\%%i
)

# Rename
@echo off

SETLOCAL enabledelayedexpansion
SET row=0
FOR /F "tokens=2, 3" %%i IN (ListWorksFolderList.txt) DO (
  SET /a row+=1
  IF !row! gtr 1 REN .\temp\%%i "%%j"
)

rem output renamed folder name
FOR /d %%i IN (temp\*) DO (
  SET temp=%%i
  (ECHO !temp:temp\=%!) >> output.txt
)


＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃
LinuxコマンドとWindowsコマンドで、それぞれListWorksフォルダーの一覧を更新日時が新しい順で取得します。
取得したリストをもとに、マッピングリストを作成します。

Linuxコマンド：
	ls -ltri --time-style="+%Y/%m/%d %H:%M:%S.%N" >/tmp/lvdata_sortbymtime.txt
	
Windowsコマンド：
	dir /a:d /TW /OD \\10.11.1.35\lv-data$\LVDATA |findstr /v /r "\.\.*$">c:\tmp\Windows_sortBymtime.txt

図を貼り付ける。



それでは、リテール帳票基盤において、リストワークフォルダの複写手順について説明させていただきます。

まず、リストワークス複写作業の問題背景について簡単に説明させていただきます。
主に2点があります、
まず一点目としては新リテール帳票基盤の List WORKS において、帳票の格納期限を設けた運用が始まったことにより、過去の帳票が旧環境にしか存在ありません。

次に2点目としては、今年の8月にホストの更新に伴い、旧環境のサーバーも停止することになりました。
このような事により、旧環境にしか存在しない過去帳票を新環境に移行することが必要になります。

なお過去帳表を新環境に移行するため、下記の方針で対応させていただくと考えております。

まず一点目としては、List WORKS に対して 、旧VMゲストを新VMゲストにV2Vで移行します。

2点目としては、旧帳票Nasの帳票データを新検証環境に新ボリューム複写することです。
本日では帳票NaSの複写方法について説明します。

2.
帳票Nasの複写手順について、下記のように考えております。
まず一点目としてはマッピングリストの作成になります。Linux サーバーを経由して圧縮作業を行う際に文字化けのフォルダ名があるため、リストワークスの各フォルダ名を識別するためのマッピングリストを作成してから後続の複写作業を行います。
マッピングリストの作成方法について次のスライドで説明させていただきます。

次に作成したマッピングリストをもとに、帳票データの圧縮で作業を行います。具体的な方法は、旧帳票Nasの帳票データをフォルダごとで圧縮して、新帳票nasに移行します。
帳票データが移動した後で、そのまま解凍作業を行います。
解凍作業が終わりましたら、作成したマッピングリストをもとに、新環境に移行したリストワークスフォルダに対してリネーム作業を行います。

次にマッピングリストの作成手順についてご説明致します。
Linuxコマンドと Windows コマンドをそれぞれで、更新日時が新しい順でリストワークのフォルダ名一覧を取得します。さらに二つのリストを販売店コードでピックアップしてマッピングリストを作成します。
実行するコマンドは下記になります。
基盤確認用フォルダだけが、識別コードを利用していないため、フォルダ名をXXXに指定してから、ファイルを移動します。

最後、論議課題について2点あります。
一点目は、NASの移行作業を行う際に、データのサイズが大きいので、数日にかけていこ作業を行います。
2点目は、移行後の正常性の判断について、現時点では下記二つの方法で考えています。
一つは Windows コマンドでファイルの名前ファイルのサイズおよびファイルの更新日時を確認します。1500件のデータの処理時間は約20秒になります。
二つ目の方法としては、Linux コマンドでファイルごとのハッシュコードを取得して比較を行います。こちらでは、1500件データの処理時間は約3秒になります


